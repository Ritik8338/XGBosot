{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success - the MySageMakerInstance is in the us-east-1 region. You will use the 811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest container for your SageMaker endpoint.\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import boto3, re, sys, math, json, os, sagemaker, urllib.request\n",
    "from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd                               \n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "# Define IAM role and assign S3 bucket\n",
    "role = get_execution_role()\n",
    "prefix = 'sagemaker/wimlds-sagemaker-xgboost-demo'\n",
    "bucket_name = 'sagemaker-us-east-1-2fd62760754591' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "\n",
    "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "\n",
    "my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15129, 21) (6484, 21)\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = np.split(data.sample(frac=1, random_state=1729), [int(0.7 * len(data))])\n",
    "print(train_data.shape, test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>...</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>17399</th>\n",
       "      <td>5153900080</td>\n",
       "      <td>2014-07-14</td>\n",
       "      <td>199000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1510</td>\n",
       "      <td>9100</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1510</td>\n",
       "      <td>0</td>\n",
       "      <td>1966</td>\n",
       "      <td>0</td>\n",
       "      <td>98003</td>\n",
       "      <td>47.3331</td>\n",
       "      <td>-122.319</td>\n",
       "      <td>1180</td>\n",
       "      <td>7220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16005</th>\n",
       "      <td>2754700095</td>\n",
       "      <td>2015-03-16</td>\n",
       "      <td>747000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.50</td>\n",
       "      <td>1710</td>\n",
       "      <td>5120</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1710</td>\n",
       "      <td>0</td>\n",
       "      <td>1920</td>\n",
       "      <td>0</td>\n",
       "      <td>98115</td>\n",
       "      <td>47.6801</td>\n",
       "      <td>-122.305</td>\n",
       "      <td>1530</td>\n",
       "      <td>5170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8382</th>\n",
       "      <td>4399200100</td>\n",
       "      <td>2015-04-28</td>\n",
       "      <td>288000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1560</td>\n",
       "      <td>9706</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1560</td>\n",
       "      <td>0</td>\n",
       "      <td>1963</td>\n",
       "      <td>0</td>\n",
       "      <td>98002</td>\n",
       "      <td>47.3191</td>\n",
       "      <td>-122.213</td>\n",
       "      <td>1510</td>\n",
       "      <td>9706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7381</th>\n",
       "      <td>3897100275</td>\n",
       "      <td>2014-10-27</td>\n",
       "      <td>460000.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.75</td>\n",
       "      <td>1660</td>\n",
       "      <td>9900</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>1660</td>\n",
       "      <td>0</td>\n",
       "      <td>1978</td>\n",
       "      <td>0</td>\n",
       "      <td>98033</td>\n",
       "      <td>47.6704</td>\n",
       "      <td>-122.184</td>\n",
       "      <td>1720</td>\n",
       "      <td>6600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16824</th>\n",
       "      <td>9477201470</td>\n",
       "      <td>2014-10-22</td>\n",
       "      <td>379950.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1270</td>\n",
       "      <td>6900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>1270</td>\n",
       "      <td>0</td>\n",
       "      <td>1977</td>\n",
       "      <td>0</td>\n",
       "      <td>98034</td>\n",
       "      <td>47.7279</td>\n",
       "      <td>-122.192</td>\n",
       "      <td>1480</td>\n",
       "      <td>7280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id       date     price  bedrooms  bathrooms  sqft_living  \\\n",
       "17399  5153900080 2014-07-14  199000.0         3       1.00         1510   \n",
       "16005  2754700095 2015-03-16  747000.0         3       1.50         1710   \n",
       "8382   4399200100 2015-04-28  288000.0         3       2.25         1560   \n",
       "7381   3897100275 2014-10-27  460000.0         3       1.75         1660   \n",
       "16824  9477201470 2014-10-22  379950.0         3       1.00         1270   \n",
       "\n",
       "       sqft_lot  floors  waterfront  view  ...  grade  sqft_above  \\\n",
       "17399      9100     1.0           0     0  ...      7        1510   \n",
       "16005      5120     2.0           0     0  ...      7        1710   \n",
       "8382       9706     1.0           0     0  ...      7        1560   \n",
       "7381       9900     2.0           0     0  ...      8        1660   \n",
       "16824      6900     1.0           0     0  ...      7        1270   \n",
       "\n",
       "       sqft_basement  yr_built  yr_renovated  zipcode      lat     long  \\\n",
       "17399              0      1966             0    98003  47.3331 -122.319   \n",
       "16005              0      1920             0    98115  47.6801 -122.305   \n",
       "8382               0      1963             0    98002  47.3191 -122.213   \n",
       "7381               0      1978             0    98033  47.6704 -122.184   \n",
       "16824              0      1977             0    98034  47.7279 -122.192   \n",
       "\n",
       "       sqft_living15  sqft_lot15  \n",
       "17399           1180        7220  \n",
       "16005           1530        5170  \n",
       "8382            1510        9706  \n",
       "7381            1720        6600  \n",
       "16824           1480        7280  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazon SageMaker's XGBoost container expects data in the libSVM or CSV data format. For this example, we'll stick to CSV. Note that the first column must be the target variable and the CSV should not include headers. Also, notice that although repetitive it's easiest to do this after the train|validation|test split rather than before. This avoids any misalignment issues due to random reordering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attributes = ['price','bedrooms', 'bathrooms', 'sqft_living',\n",
    "       'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade',\n",
    "       'sqft_basement', 'yr_built', 'yr_renovated', 'zipcode',\n",
    "       'lat', 'long', 'sqft_living15', 'sqft_lot15']\n",
    "len(attributes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data[attributes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "# train_data = scaler.fit_transform(train_data)\n",
    "# train_data = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv('train.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload training data to S3 Bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.Session().resource('s3').Bucket(bucket_name).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
    "\n",
    "s3_input_train = sagemaker.s3_input(s3_data='s3://{}/{}/train'.format(bucket_name, prefix), content_type='csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "First we'll need to specify training parameters to the estimator. This includes:\n",
    "\n",
    "- The xgboost algorithm container\n",
    "- The IAM role to use\n",
    "- Training instance type and count\n",
    "- S3 location for output data\n",
    "- Algorithm hyperparameters\n",
    "\n",
    "And then a .fit() function which specifies:\n",
    "\n",
    "S3 location for output data. In this case we have both a training and validation set which are passed in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XG Boost Hyperparamaters\n",
    "\n",
    "\n",
    "There are lot of hyperparameters, few of them are :\n",
    "\n",
    "1. Subsample\n",
    "    - Subsample ratio of the training instance. \n",
    "    - Setting it to 0.5 means that XGBoost randomly collects half of the data instances to grow trees. \n",
    "    - This prevents overfitting.\n",
    "\n",
    "        Optional\n",
    "\n",
    "        Valid values: Float. Range: [0,1].\n",
    "\n",
    "        Default value: 1\n",
    "2. Eta\n",
    "    - Step size shrinkage, prevents overfitting.\n",
    "3. Gamma\n",
    "    - Minimum loss reduction to create a partition, larger = more conservative\n",
    "4. Alpha\n",
    "    - L1 regularization term; larger = more conservative\n",
    "5. Lambda\n",
    "    - L2 regularization term; larger = more conservative\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = sagemaker.estimator.Estimator(containers[my_region],\n",
    "                                    role, \n",
    "                                    train_instance_count=1, \n",
    "                                    train_instance_type='ml.m4.xlarge',\n",
    "                                    output_path='s3://{}/{}/output'.format(bucket_name, prefix),\n",
    "                                    sagemaker_session=sess)\n",
    "xgb.set_hyperparameters(eta=0.06,\n",
    "                        alpha=0.8,\n",
    "                        lambda_bias=0.8,\n",
    "                        gamma=50,\n",
    "                        min_child_weight=6,\n",
    "                        subsample=0.5,\n",
    "                        silent=0,\n",
    "                        early_stopping_rounds=5,\n",
    "                        objective='reg:linear',\n",
    "                        num_round=1000)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb.fit({'train': s3_input_train})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "xgb_predictor = xgb.deploy(initial_instance_count=1,instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "There are many ways to compare the performance of a machine learning model, but let's start by simply comparing actual to predicted values. \n",
    "\n",
    "First we'll need to determine how we pass data into and receive data from our endpoint. Our data is currently stored as NumPy arrays in memory of our notebook instance. To send it in an HTTP POST request, we'll serialize it as a CSV string and then decode the resulting CSV.\n",
    "\n",
    "Note: For inference with CSV format, SageMaker XGBoost requires that the data does NOT include the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_array = test_data.drop([ 'price','id','sqft_above','date'], axis=1).values #load the data into an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_predictor.content_type = 'text/csv' # set the data type for an inference\n",
    "xgb_predictor.serializer = csv_serializer # set the serializer type\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6484,)\n"
     ]
    }
   ],
   "source": [
    "predictions = xgb_predictor.predict(test_data_array).decode('utf-8') # predict!\n",
    "predictions_array = np.fromstring(predictions[1:], sep=',') # and turn the prediction into an array\n",
    "print(predictions_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 score : 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "print(\"R2 score : %.2f\" % r2_score(test_data['price'],predictions_array))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
